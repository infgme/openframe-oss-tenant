<!-- source-hash: 2510ee58d12dfd803ba0af34d41ca8bf -->
Service for managing AI model metadata and capabilities across multiple providers (OpenAI, Anthropic, Google Gemini) with lazy loading and caching functionality.

## Key Components

**Interfaces:**
- `SupportedModel` - Model metadata including name, display name, provider, and context window
- `SupportedModelsResponse` - API response structure organized by provider

**SupportedModelsService Class:**
- `loadSupportedModels()` - Lazy loads model data from API with promise deduplication
- `getModelDisplayName()` - Returns human-readable model name with fallback
- `getModel()` - Retrieves complete model metadata by name
- `getAllModels()` - Returns array of all available models
- `isModelSupported()` - Checks if a model name exists
- `reset()` - Clears cache and forces reload on next access

**Singleton Export:**
- `supportedModelsService` - Ready-to-use service instance

## Usage Example

```typescript
import { supportedModelsService } from './supportedModelsService'

// Initialize and load models
await supportedModelsService.loadSupportedModels()

// Check if a model is available
if (supportedModelsService.isModelSupported('gpt-4')) {
  const model = supportedModelsService.getModel('gpt-4')
  console.log(`Context window: ${model?.contextWindow}`)
}

// Get display name for UI
const displayName = supportedModelsService.getModelDisplayName('claude-3-opus')
console.log(`Showing: ${displayName}`) // "Claude 3 Opus" instead of "claude-3-opus"

// List all available models
const allModels = supportedModelsService.getAllModels()
console.log(`Found ${allModels.length} supported models`)
```

The service automatically handles authentication via `tokenService`, implements lazy loading to avoid unnecessary API calls, and provides both raw model data and convenience methods for common operations like display name formatting.